# -*- coding: utf-8 -*-
"""batu kertas gunting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/138VzSPTZkvRkLoiXQTgf6x_VlSdbC8xd

NANDA AMALIATUS SHOLICHA

IMPORT LIBRARY
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import glob

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
import seaborn as sns

from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from google.colab import files
from tensorflow.keras.preprocessing import image

"""import dataset from github"""

!wget --no-check-certificate \
 https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
 -O /tmp/rockpaperscissors.zip

# melakukan ekstraksi pada file zip
import zipfile,os
local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close

base_dir = '../tmp/rockpaperscissors/rps-cv-images'
rock_dir = os.path.join(base_dir,'rock')
paper_dir = os.path.join(base_dir,'paper')
scissors_dir = os.path.join(base_dir,'scissors')
os.listdir(base_dir)

generator = ImageDataGenerator(
    rescale = 1/255.0,
    zoom_range=0.25,
    rotation_range = 20,
    horizontal_flip = True,
    vertical_flip = True,
    fill_mode = 'nearest',
    validation_split=0.4
)
train_generator = generator.flow_from_directory(
    base_dir,
    target_size=(150,150),
    batch_size=32,
    class_mode='categorical',
    color_mode='rgb',
    subset='training'
)
val_generator = generator.flow_from_directory(
    base_dir,
    target_size=(150,150),
    batch_size=32,
    class_mode='categorical',
    color_mode='rgb',
    subset='validation'
)

model = tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
        tf.keras.layers.MaxPooling2D(2, 2),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.Dropout(0.5),
        tf.keras.layers.Dense(3, activation=tf.nn.softmax)
])

model.summary()

class CallbackAcc(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if(logs.get('accuracy') >= 0.95):
            print("\nMencapai akurasi %2.2f%%, pelatihan telah dihentikan" %(logs.get('accuracy')*100))
            self.model.stop_training = True
callbacks = CallbackAcc()

model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

historyModel = model.fit(
    train_generator,
    steps_per_epoch = 25,
    epochs = 20,
    validation_data = val_generator,
    validation_steps = 5,
    verbose = 2,
    callbacks = [callbacks])

"""prediksi gambar menggunakan matplotlib & loss function"""

plt.subplot(1, 2, 1)
plt.plot(historyModel.history['loss'])
plt.plot(historyModel.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')

plt.subplot(1, 2, 2)
plt.plot(historyModel.history['accuracy'])
plt.plot(historyModel.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()

uploaded = files.upload()

for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))

imgplot = plt.imshow(img)
x = image.img_to_array(img)
x = np.expand_dims(x, axis = 0)
images = np.vstack([x])

classes = model.predict(images, batch_size = 10)

print(classes)
if classes[0, 0] == 1:
    print('Kertas')
elif classes[0, 1] == 1:
    print('Batu')
else:
    print('Gunting')